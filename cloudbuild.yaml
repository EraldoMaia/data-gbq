substitutions:
  _BUCKET: 'tf_bigquery_scripts_bucket'
  _PROJECT_ID: 'trusted-zone-466913'   # Projeto de destino
  _LAYER: 'trusted'                    # Camada (trusted ou refined)
  _TABLE: 'tb_sample_sales'            # Tabela alvo
  _DATASET: 'kaggle'                   # Dataset da tabela destino

logsBucket: 'cloudbuild-logs-data-gbq-466417'
timeout: 3600s

steps:

  # 0. Sincroniza todos os artefatos (substitui os existentes)
  - name: 'gcr.io/cloud-builders/gsutil'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Sincronizando artefatos da camada alterada (substituindo os existentes)..."
        gsutil -m rsync -d -r $_LAYER gs://$_BUCKET/$_LAYER
        echo "Sincronização concluída."

  # 1. Executa o DDL da Tabela no BigQuery
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Executando DDL da Tabela $_TABLE..."
        if gsutil -q stat "gs://$_BUCKET/$_LAYER/$_TABLE/ddl_$_TABLE.sql"; then
          echo "Arquivo encontrado: gs://$_BUCKET/$_LAYER/$_TABLE/ddl_$_TABLE.sql"
          bq query --project_id=$_PROJECT_ID --use_legacy_sql=false "$(gsutil cat gs://$_BUCKET/$_LAYER/$_TABLE/ddl_$_TABLE.sql)"
          echo "DDL executado com sucesso."
        else
          echo "Nenhum DDL encontrado para $_TABLE, pulando step..."
        fi

  # 2. Cria a procedure no BigQuery
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Criando/Atualizando Procedure de carga $_TABLE..."
        if gsutil -q stat "gs://$_BUCKET/$_LAYER/$_TABLE/prc_load_$_TABLE.sql"; then
          echo "Arquivo encontrado: gs://$_BUCKET/$_LAYER/$_TABLE/prc_load_$_TABLE.sql"
          bq query --project_id=$_PROJECT_ID --use_legacy_sql=false "$(gsutil cat gs://$_BUCKET/$_LAYER/$_TABLE/prc_load_$_TABLE.sql)"
          echo "Procedure criada/atualizada com sucesso."
        else
          echo "Nenhuma procedure encontrada para $_TABLE, pulando step..."
        fi
